{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf1de4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "care\n",
      "careing\n",
      "carry\n",
      "study\n",
      "studying\n",
      "study\n",
      "studied\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "str = ['cars','care','careing','carry','study','studying','studies','studied']\n",
    "for w in str:\n",
    "    print(WordNetLemmatizer().lemmatize(w,'n'))#noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3843374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "are\n",
      "were\n",
      "we\n",
      "am\n",
      "you\n",
      "your\n",
      "yours\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "str = ['is','are','were','we','am','you','your','yours']\n",
    "for w in str:\n",
    "    print(WordNetLemmatizer().lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e826d4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "be\n",
      "be\n",
      "we\n",
      "be\n",
      "you\n",
      "your\n",
      "yours\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "str = ['is','are','were','we','am','you','your','yours']\n",
    "for w in str:\n",
    "    print(WordNetLemmatizer().lemmatize(w,'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c325fa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "are\n",
      "were\n",
      "we\n",
      "am\n",
      "you\n",
      "your\n",
      "yours\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "str = ['is','are','were','we','am','you','your','yours']\n",
    "for w in str:\n",
    "    print(WordNetLemmatizer().lemmatize(w,'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dc8a399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "are\n",
      "were\n",
      "we\n",
      "am\n",
      "you\n",
      "your\n",
      "yours\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "str = ['is','are','were','we','am','you','your','yours']\n",
    "for w in str:\n",
    "    print(WordNetLemmatizer().lemmatize(w,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd713b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('is', 'VBZ'), ('are', 'VBP'), ('were', 'VBD'), ('we', 'PRP'), ('am', 'VBP'), ('you', 'PRP'), ('your', 'PRP$'), ('yours', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "#POS tagging\n",
    "str = ['is','are','were','we','am','you','your','yours']\n",
    "print(nltk.pos_tag(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "192b9eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function nltk.tag.pos_tag(tokens, tagset=None, lang='eng')>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f88b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('once', 'RB'), ('upon', 'IN'), ('a', 'DT'), ('time', 'NN'), ('there', 'EX'), ('was', 'VBD'), ('an', 'DT'), ('old', 'JJ'), ('mother', 'NN'), ('pig', 'NN'), ('who', 'WP'), ('had', 'VBD'), ('three', 'CD'), ('little', 'JJ'), ('pigs', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "stri = ['once', 'upon', 'a', 'time', 'there', 'was', 'an', 'old', 'mother', 'pig', 'who', 'had', 'three', 'little', 'pigs']\n",
    "print(nltk.pos_tag(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "275c9af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'), ('was', 'VBD'), ('a', 'DT'), ('blockbuster', 'NN'), ('.', '.')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'The was a blockbuster.'\n",
    "tokens = word_tokenize(sentence)\n",
    "tag = nltk.pos_tag(tokens)\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "703a1836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S The/DT was/VBD (NP a/DT blockbuster/NN) ./.)\n"
     ]
    }
   ],
   "source": [
    "#Extracting Noun Phrase from text :\n",
    "\n",
    "# ? - optional character\n",
    "# * - 0 or more repetations\n",
    "grammar = \"NP : {<DT>?<JJ>*<NN>} \"\n",
    "#Creating a parser :\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "#Parsing text :\n",
    "output = parser.parse(tag)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "103ad2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP The/DT was/VBD a/DT blockbuster/NN ./.))\n"
     ]
    }
   ],
   "source": [
    "#Chinking example :\n",
    "# * - 0 or more repetations\n",
    "# + - 1 or more repetations\n",
    "\n",
    "#Here we are taking the whole string and then\n",
    "#excluding adjectives from that chunk.\n",
    "\n",
    "grammar = r\"\"\" NP: {<.*>+} \n",
    "               }<JJ>+{\"\"\"\n",
    "\n",
    "#Creating parser :\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "#parsing string :\n",
    "output = parser.parse(tag)\n",
    "print(output)\n",
    "\n",
    "#To visualize :\n",
    "output.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69e586da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9df61c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1922137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('fun.n.01')\n",
      "Synset('fun.n.02')\n",
      "Synset('fun.n.03')\n",
      "Synset('playfulness.n.02')\n"
     ]
    }
   ],
   "source": [
    "for words in wordnet.synsets('fun'):\n",
    "    print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c7b7d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun.n.01\n",
      "activities that are enjoyable or amusing\n",
      "['I do it for the fun of it', 'he is fun to have around']\n",
      "\n",
      "\n",
      "fun.n.02\n",
      "verbal wit or mockery (often at another's expense but not to be taken seriously)\n",
      "['he became a figure of fun', 'he said it in sport']\n",
      "\n",
      "\n",
      "fun.n.03\n",
      "violent and excited activity\n",
      "['she asked for money and then the fun began', 'they began to fight like fun']\n",
      "\n",
      "\n",
      "playfulness.n.02\n",
      "a disposition to find (or make) causes for amusement\n",
      "['her playfulness surprised me', 'he was fun to be with']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for words in wordnet.synsets('fun'):\n",
    "    print(words.name())\n",
    "    print(words.definition())\n",
    "    print(words.examples())\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e94c61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt.n.01\n",
      "earnest and conscientious activity intended to do or accomplish something\n",
      "['made an effort to cover all the reading material', 'wished him luck in his endeavor', 'she gave it a good try']\n",
      "\n",
      "\n",
      "try.v.01\n",
      "make an effort or attempt\n",
      "['He tried to shake off his fears', 'The infant had essayed a few wobbly steps', 'The police attempted to stop the thief', 'He sought to improve himself', 'She always seeks to do good in the world']\n",
      "\n",
      "\n",
      "test.v.01\n",
      "put to the test, as for its quality, or give experimental use to\n",
      "['This approach has been tried with good results', 'Test this recipe']\n",
      "\n",
      "\n",
      "judge.v.05\n",
      "put on trial or hear a case and sit as the judge at the trial of\n",
      "['The football star was tried for the murder of his wife', 'The judge tried both father and son in separate trials']\n",
      "\n",
      "\n",
      "sample.v.01\n",
      "take a sample of\n",
      "['Try these new crackers', 'Sample the regional dishes']\n",
      "\n",
      "\n",
      "hear.v.03\n",
      "examine or hear (evidence or a case) by judicial process\n",
      "['The jury had heard all the evidence', 'The case will be tried in California']\n",
      "\n",
      "\n",
      "try.v.06\n",
      "give pain or trouble to\n",
      "[\"I've been sorely tried by these students\"]\n",
      "\n",
      "\n",
      "try.v.07\n",
      "test the limits of\n",
      "['You are trying my patience!']\n",
      "\n",
      "\n",
      "try.v.08\n",
      "melt (fat or lard) in order to separate out impurities\n",
      "['try the yak butter', 'render fat in a casserole']\n",
      "\n",
      "\n",
      "try_on.v.01\n",
      "put on a garment in order to see whether it fits and looks nice\n",
      "['Try on this sweater to see how it looks']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for words in wordnet.synsets('try'):\n",
    "    print(words.name())\n",
    "    print(words.definition())\n",
    "    print(words.examples())\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "041d879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jeer.n.01\n",
      "showing your contempt by derision\n",
      "[]\n",
      "\n",
      "\n",
      "Lemma('jeer.n.01.jeer')\n",
      "Lemma('jeer.n.01.jeering')\n",
      "Lemma('jeer.n.01.mockery')\n",
      "Lemma('jeer.n.01.scoff')\n",
      "Lemma('jeer.n.01.scoffing')\n",
      "-------------------------------\n",
      "parody.n.01\n",
      "a composition that imitates or misrepresents somebody's style, usually in a humorous way\n",
      "[]\n",
      "\n",
      "\n",
      "Lemma('parody.n.01.parody')\n",
      "Lemma('parody.n.01.lampoon')\n",
      "Lemma('parody.n.01.spoof')\n",
      "Lemma('parody.n.01.sendup')\n",
      "Lemma('parody.n.01.mockery')\n",
      "Lemma('parody.n.01.takeoff')\n",
      "Lemma('parody.n.01.burlesque')\n",
      "Lemma('parody.n.01.travesty')\n",
      "Lemma('parody.n.01.charade')\n",
      "Lemma('parody.n.01.pasquinade')\n",
      "Lemma('parody.n.01.put-on')\n",
      "-------------------------------\n",
      "parody.n.02\n",
      "humorous or satirical mimicry\n",
      "[]\n",
      "\n",
      "\n",
      "Lemma('parody.n.02.parody')\n",
      "Lemma('parody.n.02.mockery')\n",
      "Lemma('parody.n.02.takeoff')\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for words in wordnet.synsets('mockery'):\n",
    "    print(words.name())\n",
    "    print(words.definition())\n",
    "    print(words.examples())\n",
    "    print('\\n')\n",
    "    for wor in words.lemmas():\n",
    "        print(wor)\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6bd77cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey.n.01\n",
      "a detailed critical inspection\n",
      "[]\n",
      "\n",
      "\n",
      "Lemma('survey.n.01.survey')\n",
      "Lemma('survey.n.01.study')\n",
      "-------------------------------\n",
      "study.n.02\n",
      "applying the mind to learning and understanding a subject (especially by reading)\n",
      "['mastering a second language requires a lot of work', 'no schools offer graduate study in interior design']\n",
      "\n",
      "\n",
      "Lemma('study.n.02.study')\n",
      "Lemma('study.n.02.work')\n",
      "-------------------------------\n",
      "report.n.01\n",
      "a written document describing the findings of some individual or group\n",
      "['this accords with the recent study by Hill and Dale']\n",
      "\n",
      "\n",
      "Lemma('report.n.01.report')\n",
      "Lemma('report.n.01.study')\n",
      "Lemma('report.n.01.written_report')\n",
      "-------------------------------\n",
      "study.n.04\n",
      "a state of deep mental absorption\n",
      "['she is in a deep study']\n",
      "\n",
      "\n",
      "Lemma('study.n.04.study')\n",
      "-------------------------------\n",
      "study.n.05\n",
      "a room used for reading and writing and studying\n",
      "['he knocked lightly on the closed door of the study']\n",
      "\n",
      "\n",
      "Lemma('study.n.05.study')\n",
      "-------------------------------\n",
      "discipline.n.01\n",
      "a branch of knowledge\n",
      "['in what discipline is his doctorate?', 'teachers should be well trained in their subject', 'anthropology is the study of human beings']\n",
      "\n",
      "\n",
      "Lemma('discipline.n.01.discipline')\n",
      "Lemma('discipline.n.01.subject')\n",
      "Lemma('discipline.n.01.subject_area')\n",
      "Lemma('discipline.n.01.subject_field')\n",
      "Lemma('discipline.n.01.field')\n",
      "Lemma('discipline.n.01.field_of_study')\n",
      "Lemma('discipline.n.01.study')\n",
      "Lemma('discipline.n.01.bailiwick')\n",
      "-------------------------------\n",
      "sketch.n.01\n",
      "preliminary drawing for later elaboration\n",
      "['he made several studies before starting to paint']\n",
      "\n",
      "\n",
      "Lemma('sketch.n.01.sketch')\n",
      "Lemma('sketch.n.01.study')\n",
      "-------------------------------\n",
      "cogitation.n.02\n",
      "attentive consideration and meditation\n",
      "['after much cogitation he rejected the offer']\n",
      "\n",
      "\n",
      "Lemma('cogitation.n.02.cogitation')\n",
      "Lemma('cogitation.n.02.study')\n",
      "-------------------------------\n",
      "study.n.09\n",
      "someone who memorizes quickly and easily (as the lines for a part in a play)\n",
      "['he is a quick study']\n",
      "\n",
      "\n",
      "Lemma('study.n.09.study')\n",
      "-------------------------------\n",
      "study.n.10\n",
      "a composition intended to develop one aspect of the performer's technique\n",
      "['a study in spiccato bowing']\n",
      "\n",
      "\n",
      "Lemma('study.n.10.study')\n",
      "-------------------------------\n",
      "analyze.v.01\n",
      "consider in detail and subject to an analysis in order to discover essential features or meaning\n",
      "['analyze a sonnet by Shakespeare', 'analyze the evidence in a criminal trial', 'analyze your real motives']\n",
      "\n",
      "\n",
      "Lemma('analyze.v.01.analyze')\n",
      "Lemma('analyze.v.01.analyse')\n",
      "Lemma('analyze.v.01.study')\n",
      "Lemma('analyze.v.01.examine')\n",
      "Lemma('analyze.v.01.canvass')\n",
      "Lemma('analyze.v.01.canvas')\n",
      "-------------------------------\n",
      "study.v.02\n",
      "be a student; follow a course of study; be enrolled at an institute of learning\n",
      "[]\n",
      "\n",
      "\n",
      "Lemma('study.v.02.study')\n",
      "-------------------------------\n",
      "study.v.03\n",
      "give careful consideration to\n",
      "['consider the possibility of moving']\n",
      "\n",
      "\n",
      "Lemma('study.v.03.study')\n",
      "Lemma('study.v.03.consider')\n",
      "-------------------------------\n",
      "learn.v.04\n",
      "be a student of a certain subject\n",
      "['She is reading for the bar exam']\n",
      "\n",
      "\n",
      "Lemma('learn.v.04.learn')\n",
      "Lemma('learn.v.04.study')\n",
      "Lemma('learn.v.04.read')\n",
      "Lemma('learn.v.04.take')\n",
      "-------------------------------\n",
      "study.v.05\n",
      "learn by reading books\n",
      "['He is studying geology in his room', 'I have an exam next week; I must hit the books now']\n",
      "\n",
      "\n",
      "Lemma('study.v.05.study')\n",
      "Lemma('study.v.05.hit_the_books')\n",
      "-------------------------------\n",
      "study.v.06\n",
      "think intently and at length, as for spiritual purposes\n",
      "['He is meditating in his study']\n",
      "\n",
      "\n",
      "Lemma('study.v.06.study')\n",
      "Lemma('study.v.06.meditate')\n",
      "Lemma('study.v.06.contemplate')\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for words in wordnet.synsets('study'):\n",
    "    print(words.name())\n",
    "    print(words.definition())\n",
    "    print(words.examples())\n",
    "    print('\\n')\n",
    "    for wor in words.lemmas():\n",
    "        print(wor)\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a308442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('dramatic_composition.n.01')]\n"
     ]
    }
   ],
   "source": [
    "word = wordnet.synsets(\"Play\")[0]\n",
    "\n",
    "#Find more abstract term :\n",
    "print(word.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f866a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('grand_guignol.n.01'),\n",
       " Synset('miracle_play.n.01'),\n",
       " Synset('morality_play.n.01'),\n",
       " Synset('mystery_play.n.01'),\n",
       " Synset('passion_play.n.01'),\n",
       " Synset('playlet.n.01'),\n",
       " Synset('satyr_play.n.01'),\n",
       " Synset('theater_of_the_absurd.n.01')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99159bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "#Similarity in words :\n",
    "word1 = wordnet.synsets(\"ship\",\"n\")[0]\n",
    "\n",
    "word2 = wordnet.synsets(\"bike\",\"n\")[0] \n",
    "\n",
    "#Check similarity :\n",
    "print(word1.wup_similarity(word2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "979ae31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "#Similarity in words :\n",
    "word1 = wordnet.synsets(\"brakes\",\"n\")[0]\n",
    "\n",
    "word2 = wordnet.synsets(\"bike\",\"n\")[0] \n",
    "\n",
    "#Check similarity :\n",
    "print(word1.wup_similarity(word2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405acc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
